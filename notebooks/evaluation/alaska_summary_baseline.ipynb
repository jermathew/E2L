{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:08.687669Z",
     "start_time": "2020-12-08T16:09:08.683864Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '../../'\n",
    "src_dir = 'src'\n",
    "data_dir = 'data/corpus'\n",
    "models_dir = 'data/models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:08.692616Z",
     "start_time": "2020-12-08T16:09:08.690019Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:08.698406Z",
     "start_time": "2020-12-08T16:09:08.695012Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir, src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:08.723442Z",
     "start_time": "2020-12-08T16:09:08.720862Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_filename = 'alaska_corpus.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.273366Z",
     "start_time": "2020-12-08T16:09:08.890546Z"
    }
   },
   "outputs": [],
   "source": [
    "from training import TrainingCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.289607Z",
     "start_time": "2020-12-08T16:09:10.275016Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()\n",
    "corpus.load(os.path.join(root_dir, data_dir, corpus_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.300042Z",
     "start_time": "2020-12-08T16:09:10.291673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds pseudo-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.303849Z",
     "start_time": "2020-12-08T16:09:10.301645Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.307530Z",
     "start_time": "2020-12-08T16:09:10.305332Z"
    }
   },
   "outputs": [],
   "source": [
    "pseudodocs_dict = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.512451Z",
     "start_time": "2020-12-08T16:09:10.503784Z"
    }
   },
   "outputs": [],
   "source": [
    "for doc_id in corpus.docs:\n",
    "    text = corpus.get_text(doc_id)\n",
    "    label = corpus.target[doc_id][0]\n",
    "    pseudodocs_dict[label] += ' ' + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T09:34:52.385404Z",
     "start_time": "2020-12-03T09:34:52.380486Z"
    }
   },
   "source": [
    "## Summarize pseudo-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:10.994325Z",
     "start_time": "2020-12-08T16:09:10.990314Z"
    }
   },
   "outputs": [],
   "source": [
    "entities = list(pseudodocs_dict.keys())\n",
    "num_entities = len(entities)\n",
    "pseudodocs = [pseudodocs_dict[e_id] for e_id in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:11.275121Z",
     "start_time": "2020-12-08T16:09:11.272156Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-large-cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:31.034351Z",
     "start_time": "2020-12-08T16:09:11.472285Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:09:31.042278Z",
     "start_time": "2020-12-08T16:09:31.038029Z"
    }
   },
   "outputs": [],
   "source": [
    "min_len = 10\n",
    "max_len = 100\n",
    "do_sample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T16:20:58.325426Z",
     "start_time": "2020-12-08T16:09:31.044680Z"
    }
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "for i in range(num_entities):\n",
    "    doc = pseudodocs[i].lower()\n",
    "    encoded_doc = tokenizer([doc], padding=True, truncation=True, return_tensors='pt')\n",
    "    summary_ids = model.generate(encoded_doc['input_ids'], min_length=min_len, max_length=max_len, do_sample=do_sample)\n",
    "    summary_text = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "    summaries.append(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save summaries to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:01:42.152436Z",
     "start_time": "2020-12-08T17:01:42.145812Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:01:42.469162Z",
     "start_time": "2020-12-08T17:01:42.444818Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>Nikon d3200 digital slr camera, 24.2 megapixel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#23</td>\n",
       "      <td>Ebay canon eos 7d is on sale for $734.39. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#18</td>\n",
       "      <td>Camerafarm australia canon eos 60d 18.1x optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#36</td>\n",
       "      <td>ebay nikon d3100 + 18-55/3.5-5.6 vr + 55-300/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#41</td>\n",
       "      <td>Ebay buy nikon d5200 digital slr camera, black...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity                                            summary\n",
       "0  ENTITY#44  Nikon d3200 digital slr camera, 24.2 megapixel...\n",
       "1  ENTITY#23  Ebay canon eos 7d is on sale for $734.39. The ...\n",
       "2  ENTITY#18  Camerafarm australia canon eos 60d 18.1x optic...\n",
       "3  ENTITY#36   ebay nikon d3100 + 18-55/3.5-5.6 vr + 55-300/...\n",
       "4  ENTITY#41  Ebay buy nikon d5200 digital slr camera, black..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_summaries_df = pd.DataFrame([(e, s) for e, s in zip(entities, summaries)], columns=['entity', 'summary'])\n",
    "raw_summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:01:43.812814Z",
     "start_time": "2020-12-08T17:01:43.561222Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_summaries_filename = 'raw_summary_alaska.xlsx'\n",
    "raw_summaries_filepath = os.path.join(root_dir, 'data/terms', raw_summaries_filename)\n",
    "raw_summaries_df.to_excel(raw_summaries_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:03:11.356228Z",
     "start_time": "2020-12-08T17:03:11.350803Z"
    }
   },
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:22:17.300008Z",
     "start_time": "2020-12-08T17:22:17.284502Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_mix(seq, subseq):\n",
    "    n = len(seq)\n",
    "    m = len(subseq)\n",
    "    for i in range(n - m + 1):\n",
    "        if seq[i] == subseq[0] and seq[i:i + m] == subseq:\n",
    "            yield range(i, i + m)\n",
    "            \n",
    "\n",
    "def get_chunk_document(chunks, text) -> list:\n",
    "    tokens = TrainingCorpus.tokenize(text.lower())\n",
    "    \n",
    "    if len(chunks) > 0:\n",
    "        for k_chunk in chunks:\n",
    "            chunk = k_chunk.split('_')\n",
    "            replacements = [r for r in find_mix(tokens, chunk)]\n",
    "            l, f = 0, []\n",
    "            \n",
    "            while l < len(tokens):\n",
    "                replaced = False\n",
    "                \n",
    "                for r in replacements:\n",
    "                    if l in r:\n",
    "                        replaced = True\n",
    "                        f.append(chunk)\n",
    "                        l += len(chunk)\n",
    "                        break\n",
    "                    else:\n",
    "                        pass\n",
    "                if not replaced:\n",
    "                    f.append(tokens[l])\n",
    "                    l += 1\n",
    "            \n",
    "            new_tokens = []\n",
    "            \n",
    "            for x in f:\n",
    "                if isinstance(x, list):\n",
    "                    new_tokens.append(\"_\".join(x))\n",
    "                else:\n",
    "                    new_tokens.append(x)\n",
    "            tokens = new_tokens\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:07:48.846109Z",
     "start_time": "2020-12-08T17:07:48.840096Z"
    }
   },
   "source": [
    "### Get chunk document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:22:20.080806Z",
     "start_time": "2020-12-08T17:22:20.076854Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:22:23.799886Z",
     "start_time": "2020-12-08T17:22:22.423821Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d51c500b26e42c5913fd0fc1bc8006c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary_chunks = []\n",
    "spacy_model_name = 'en_core_web_sm'\n",
    "spacy_model = spacy.load(spacy_model_name)\n",
    "\n",
    "for s in tqdm(summaries):\n",
    "    chunks = []\n",
    "    for chunk in spacy_model(s.lower()).noun_chunks:\n",
    "        c = '_'.join(TrainingCorpus.tokenize(chunk.text))\n",
    "        if c:\n",
    "            chunks.append(c)\n",
    "    \n",
    "    chunk_doc = get_chunk_document(chunks, s)\n",
    "    summary_chunks.append(chunk_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:22:30.401321Z",
     "start_time": "2020-12-08T17:22:30.396534Z"
    }
   },
   "source": [
    "### Save chunks to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:24:26.265006Z",
     "start_time": "2020-12-08T17:24:26.254817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon_d3200_digital_slr_camera 24_2_megapixels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#23</td>\n",
       "      <td>ebay_canon_eos_7d sale 734 39. camera 28_135mm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#18</td>\n",
       "      <td>camerafarm_australia canon eos 60d 18 1x optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#36</td>\n",
       "      <td>ebay_nikon_d3100 18-55/3_5-5_6_vr 55-300/4 5 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#41</td>\n",
       "      <td>ebay buy nikon_d5200_digital_slr_camera black ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity                                            summary\n",
       "0  ENTITY#44  nikon_d3200_digital_slr_camera 24_2_megapixels...\n",
       "1  ENTITY#23  ebay_canon_eos_7d sale 734 39. camera 28_135mm...\n",
       "2  ENTITY#18  camerafarm_australia canon eos 60d 18 1x optic...\n",
       "3  ENTITY#36  ebay_nikon_d3100 18-55/3_5-5_6_vr 55-300/4 5 5...\n",
       "4  ENTITY#41  ebay buy nikon_d5200_digital_slr_camera black ..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df = pd.DataFrame([(e, s) for e, s in zip(entities, summary_chunks)], columns=['entity', 'summary'])\n",
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:30:21.135549Z",
     "start_time": "2020-12-08T17:30:21.117272Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks_filename = 'chunk_summary_alaska.xlsx'\n",
    "chunks_filepath = os.path.join(root_dir, 'data/terms', chunks_filename)\n",
    "chunks_df.to_excel(chunks_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute tf-idf on each pseudo-document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:45.524660Z",
     "start_time": "2020-12-07T12:25:45.275573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_pseudodocs = []\n",
    "\n",
    "for i in range(num_entities):\n",
    "    doc = pseudodocs[i]\n",
    "    clean_doc = ' '.join(TrainingCorpus.tokenize(doc))\n",
    "    clean_pseudodocs.append(clean_doc)\n",
    "\n",
    "len(clean_pseudodocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-05T11:18:53.469356Z",
     "start_time": "2020-12-05T11:18:53.464468Z"
    }
   },
   "source": [
    "# Fit tf-idf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:45.528088Z",
     "start_time": "2020-12-07T12:25:45.525960Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:45.547624Z",
     "start_time": "2020-12-07T12:25:45.529323Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/anaconda3/envs/testenv/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=False, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function <lambda> at 0x7fa90c0e2820>, use_idf=True,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False, tokenizer=lambda x: x.split())\n",
    "vectorizer.fit(clean_pseudodocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save tf-idf weights into a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:45.563193Z",
     "start_time": "2020-12-07T12:25:45.548830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1224)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_docs = vectorizer.transform(clean_pseudodocs)\n",
    "vectorized_docs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.544395Z",
     "start_time": "2020-12-07T12:25:45.565015Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_weights = []\n",
    "\n",
    "for i in range(num_entities):\n",
    "    doc_vector = vectorized_docs[i].toarray().reshape(-1)\n",
    "    weights = {}\n",
    "    \n",
    "    for j, w in enumerate(doc_vector):\n",
    "        feature_name = vectorizer.get_feature_names()[j]\n",
    "        if w > 0:\n",
    "            weights[feature_name] = w\n",
    "    \n",
    "    tfidf_weights.append(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute baseline summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.549027Z",
     "start_time": "2020-12-07T12:25:58.546443Z"
    }
   },
   "outputs": [],
   "source": [
    "min_len = 1\n",
    "max_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.553017Z",
     "start_time": "2020-12-07T12:25:58.550683Z"
    }
   },
   "outputs": [],
   "source": [
    "tolerance = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.558191Z",
     "start_time": "2020-12-07T12:25:58.554661Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_score(idx, text):\n",
    "    weights = tfidf_weights[idx]\n",
    "    tokenized_text = TrainingCorpus.tokenize(text.lower())\n",
    "    score = 0\n",
    "    \n",
    "    if tokenized_text:\n",
    "        for token in tokenized_text:\n",
    "            if token in weights:\n",
    "                score += weights[token]\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.563533Z",
     "start_time": "2020-12-07T12:25:58.560541Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.567172Z",
     "start_time": "2020-12-07T12:25:58.565047Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_percentile = 98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.605310Z",
     "start_time": "2020-12-07T12:25:58.568566Z"
    }
   },
   "outputs": [],
   "source": [
    "final_summaries = []\n",
    "\n",
    "for i in range(num_entities):\n",
    "    summary = summaries[i].split()\n",
    "    weights = list(tfidf_weights[i].values())\n",
    "    threshold = np.percentile(weights, threshold_percentile)\n",
    "    below_threshold_count = 0\n",
    "    prev_score = 0\n",
    "    \n",
    "    for j in range(min_len, max_len):\n",
    "        selected_summary_tokens = summary[:j]\n",
    "        selected_summary = ' '.join(selected_summary_tokens)\n",
    "        score = compute_score(i, selected_summary)\n",
    "        delta_score = score - prev_score\n",
    "        \n",
    "        if delta_score >= threshold:\n",
    "            below_threshold_count = 0\n",
    "        else:\n",
    "            below_threshold_count += 1\n",
    "            \n",
    "        if below_threshold_count > tolerance:\n",
    "            final_summary = ' '.join(selected_summary_tokens[:j-tolerance-1])\n",
    "            break\n",
    "                \n",
    "        else:\n",
    "            final_summary = selected_summary\n",
    "        \n",
    "        prev_score = score\n",
    "    \n",
    "    final_summaries.append(final_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:25:58.610437Z",
     "start_time": "2020-12-07T12:25:58.606841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nikon d3200 digital slr camera, 24.2 megapixels for less',\n",
       " 'Ebay canon eos 7d is on sale for $734.39.',\n",
       " 'Camerafarm australia canon eos 60d 18.1x optical zoom -',\n",
       " 'ebay nikon d3100',\n",
       " 'Ebay buy nikon d5200 digital slr camera, black (body',\n",
       " 'Nikon d5100 16.2',\n",
       " 'ebay nikon d7000',\n",
       " 'Canon eos 70d',\n",
       " 'Nikon d5300 24.2 mp cmos digital slr camera with',\n",
       " 'Canon eos 5d mark iii kit with ef 24-105mm',\n",
       " 'Ebay canon eos 5d mark ii 21 1 mp',\n",
       " 'Nikon d90',\n",
       " 'Buy nikon d800 digital slr body, 36.3mp (body only)',\n",
       " 'Nikon d610',\n",
       " 'Nikon d3300',\n",
       " 'Ebay nikon 1 j1 mirrorless 10-30 mm price in',\n",
       " 'ebay nikon d80 10.2mp digital slr camera kit on',\n",
       " 'Nikon d300 12',\n",
       " 'Nikon 1 j3',\n",
       " 'Olympus om-d e-m5']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a DataFrame out of summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:32:16.559914Z",
     "start_time": "2020-12-07T12:32:16.541366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>Nikon d3200 digital slr camera, 24.2 megapixel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#23</td>\n",
       "      <td>Ebay canon eos 7d is on sale for $734.39.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#18</td>\n",
       "      <td>Camerafarm australia canon eos 60d 18.1x optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#36</td>\n",
       "      <td>ebay nikon d3100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#41</td>\n",
       "      <td>Ebay buy nikon d5200 digital slr camera, black...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity                                            summary\n",
       "0  ENTITY#44  Nikon d3200 digital slr camera, 24.2 megapixel...\n",
       "1  ENTITY#23          Ebay canon eos 7d is on sale for $734.39.\n",
       "2  ENTITY#18  Camerafarm australia canon eos 60d 18.1x optic...\n",
       "3  ENTITY#36                                   ebay nikon d3100\n",
       "4  ENTITY#41  Ebay buy nikon d5200 digital slr camera, black..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([(e, s) for e, s in zip(entities, final_summaries)], columns=['entity', 'summary'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DataFrame to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-07T12:37:59.445272Z",
     "start_time": "2020-12-07T12:37:59.433764Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'summary_baseline_alaska.xlsx'\n",
    "filepath = os.path.join(root_dir, 'data/terms', filename)\n",
    "df.to_excel(filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
