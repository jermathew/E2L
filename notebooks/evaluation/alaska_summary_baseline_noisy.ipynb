{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:06.230476Z",
     "start_time": "2021-03-17T14:39:06.225623Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '../../'\n",
    "src_dir = 'src'\n",
    "data_dir = 'data/corpus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:07.525089Z",
     "start_time": "2021-03-17T14:39:07.521603Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:08.432391Z",
     "start_time": "2021-03-17T14:39:08.429119Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir, src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:24.837321Z",
     "start_time": "2021-03-17T14:39:24.834733Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_filename = 'alaska_corpus_noisy.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:26.086834Z",
     "start_time": "2021-03-17T14:39:25.039835Z"
    }
   },
   "outputs": [],
   "source": [
    "from training import TrainingCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:26.104527Z",
     "start_time": "2021-03-17T14:39:26.088746Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()\n",
    "corpus.load(os.path.join(root_dir, data_dir, corpus_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:26.121389Z",
     "start_time": "2021-03-17T14:39:26.107580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2171"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builds pseudo-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:32.896508Z",
     "start_time": "2021-03-17T14:39:32.892379Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:33.286091Z",
     "start_time": "2021-03-17T14:39:33.283530Z"
    }
   },
   "outputs": [],
   "source": [
    "pseudodocs_dict = defaultdict(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:33.599386Z",
     "start_time": "2021-03-17T14:39:33.587473Z"
    }
   },
   "outputs": [],
   "source": [
    "for doc_id in corpus.docs:\n",
    "    text = corpus.get_text(doc_id)\n",
    "    label = corpus.target[doc_id][0]\n",
    "    pseudodocs_dict[label] += ' ' + text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-03T09:34:52.385404Z",
     "start_time": "2020-12-03T09:34:52.380486Z"
    }
   },
   "source": [
    "## Summarize pseudo-docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:34.974882Z",
     "start_time": "2021-03-17T14:39:34.970060Z"
    }
   },
   "outputs": [],
   "source": [
    "entities = list(pseudodocs_dict.keys())\n",
    "num_entities = len(entities)\n",
    "pseudodocs = [pseudodocs_dict[e_id] for e_id in entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:39:36.965090Z",
     "start_time": "2021-03-17T14:39:36.961515Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'facebook/bart-large-cnn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:40:03.784318Z",
     "start_time": "2021-03-17T14:39:38.875272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d29000da4b14b138cfe3d3ab11b9783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Downloading'), FloatProgress(value=0.0, max=1399.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:40:06.260867Z",
     "start_time": "2021-03-17T14:40:06.257762Z"
    }
   },
   "outputs": [],
   "source": [
    "min_len = 10\n",
    "max_len = 100\n",
    "do_sample = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:41:16.543124Z",
     "start_time": "2021-03-17T14:40:06.865627Z"
    }
   },
   "outputs": [],
   "source": [
    "summaries = []\n",
    "\n",
    "for i in range(num_entities):\n",
    "    doc = pseudodocs[i].lower()\n",
    "    encoded_doc = tokenizer([doc], padding=True, truncation=True, return_tensors='pt')\n",
    "    summary_ids = model.generate(encoded_doc['input_ids'], min_length=min_len, max_length=max_len, do_sample=do_sample)\n",
    "    summary_text = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids][0]\n",
    "    summaries.append(summary_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save summaries to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:49.274103Z",
     "start_time": "2021-03-17T14:42:49.263970Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:49.606490Z",
     "start_time": "2021-03-17T14:42:49.587809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>Nikon d3200 digital slr camera, 24.2 megapixel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#23</td>\n",
       "      <td>Ebay canon eos 7d is on sale for $734.39. The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#18</td>\n",
       "      <td>Camerafarm australia canon eos 60d 18.1x optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#36</td>\n",
       "      <td>ebay nikon d3100 + 18-55/3.5-5.6 vr + 55-300/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#41</td>\n",
       "      <td>Ebay buy nikon d5200 digital slr camera, black...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity                                            summary\n",
       "0  ENTITY#44  Nikon d3200 digital slr camera, 24.2 megapixel...\n",
       "1  ENTITY#23  Ebay canon eos 7d is on sale for $734.39. The ...\n",
       "2  ENTITY#18  Camerafarm australia canon eos 60d 18.1x optic...\n",
       "3  ENTITY#36   ebay nikon d3100 + 18-55/3.5-5.6 vr + 55-300/...\n",
       "4  ENTITY#41  Ebay buy nikon d5200 digital slr camera, black..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_summaries_df = pd.DataFrame([(e, s) for e, s in zip(entities, summaries)], columns=['entity', 'summary'])\n",
    "raw_summaries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:53.043393Z",
     "start_time": "2021-03-17T14:42:52.695455Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_summaries_filename = 'raw_summary_alaska_noisy.xlsx'\n",
    "raw_summaries_filepath = os.path.join(root_dir, 'data/terms', raw_summaries_filename)\n",
    "raw_summaries_df.to_excel(raw_summaries_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:03:11.356228Z",
     "start_time": "2020-12-08T17:03:11.350803Z"
    }
   },
   "source": [
    "### Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:54.716027Z",
     "start_time": "2021-03-17T14:42:54.706820Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_mix(seq, subseq):\n",
    "    n = len(seq)\n",
    "    m = len(subseq)\n",
    "    for i in range(n - m + 1):\n",
    "        if seq[i] == subseq[0] and seq[i:i + m] == subseq:\n",
    "            yield range(i, i + m)\n",
    "            \n",
    "\n",
    "def get_chunk_document(chunks, text) -> list:\n",
    "    tokens = TrainingCorpus.tokenize(text.lower())\n",
    "    \n",
    "    if len(chunks) > 0:\n",
    "        for k_chunk in chunks:\n",
    "            chunk = k_chunk.split('_')\n",
    "            replacements = [r for r in find_mix(tokens, chunk)]\n",
    "            l, f = 0, []\n",
    "            \n",
    "            while l < len(tokens):\n",
    "                replaced = False\n",
    "                \n",
    "                for r in replacements:\n",
    "                    if l in r:\n",
    "                        replaced = True\n",
    "                        f.append(chunk)\n",
    "                        l += len(chunk)\n",
    "                        break\n",
    "                    else:\n",
    "                        pass\n",
    "                if not replaced:\n",
    "                    f.append(tokens[l])\n",
    "                    l += 1\n",
    "            \n",
    "            new_tokens = []\n",
    "            \n",
    "            for x in f:\n",
    "                if isinstance(x, list):\n",
    "                    new_tokens.append(\"_\".join(x))\n",
    "                else:\n",
    "                    new_tokens.append(x)\n",
    "            tokens = new_tokens\n",
    "    \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:07:48.846109Z",
     "start_time": "2020-12-08T17:07:48.840096Z"
    }
   },
   "source": [
    "### Get chunk document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:55.789045Z",
     "start_time": "2021-03-17T14:42:55.786496Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:42:57.297324Z",
     "start_time": "2021-03-17T14:42:56.337648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b75715841142e597b769d7fe11b3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary_chunks = []\n",
    "spacy_model_name = 'en_core_web_sm'\n",
    "spacy_model = spacy.load(spacy_model_name)\n",
    "\n",
    "for s in tqdm(summaries):\n",
    "    chunks = []\n",
    "    for chunk in spacy_model(s.lower()).noun_chunks:\n",
    "        c = '_'.join(TrainingCorpus.tokenize(chunk.text))\n",
    "        if c:\n",
    "            chunks.append(c)\n",
    "    \n",
    "    chunk_doc = get_chunk_document(chunks, s)\n",
    "    summary_chunks.append(chunk_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-08T17:22:30.401321Z",
     "start_time": "2020-12-08T17:22:30.396534Z"
    }
   },
   "source": [
    "### Save chunks to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:43:01.953251Z",
     "start_time": "2021-03-17T14:43:01.942364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon_d3200_digital_slr_camera 24_2_megapixels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#23</td>\n",
       "      <td>ebay_canon_eos_7d sale 734 39. camera 28_135mm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#18</td>\n",
       "      <td>camerafarm_australia canon eos 60d 18 1x optic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#36</td>\n",
       "      <td>ebay_nikon_d3100 18-55/3_5-5_6_vr 55-300/4 5 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#41</td>\n",
       "      <td>ebay buy nikon_d5200_digital_slr_camera black ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity                                            summary\n",
       "0  ENTITY#44  nikon_d3200_digital_slr_camera 24_2_megapixels...\n",
       "1  ENTITY#23  ebay_canon_eos_7d sale 734 39. camera 28_135mm...\n",
       "2  ENTITY#18  camerafarm_australia canon eos 60d 18 1x optic...\n",
       "3  ENTITY#36  ebay_nikon_d3100 18-55/3_5-5_6_vr 55-300/4 5 5...\n",
       "4  ENTITY#41  ebay buy nikon_d5200_digital_slr_camera black ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks_df = pd.DataFrame([(e, s) for e, s in zip(entities, summary_chunks)], columns=['entity', 'summary'])\n",
    "chunks_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-17T14:43:07.713007Z",
     "start_time": "2021-03-17T14:43:07.699780Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks_filename = 'chunk_summary_alaska_noisy.xlsx'\n",
    "chunks_filepath = os.path.join(root_dir, 'data/terms', chunks_filename)\n",
    "chunks_df.to_excel(chunks_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
