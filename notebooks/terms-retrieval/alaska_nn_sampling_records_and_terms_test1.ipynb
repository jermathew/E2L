{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find cluster related terms using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:12:59.105182Z",
     "start_time": "2021-01-10T17:12:59.102460Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '../..'\n",
    "data_dir = 'data'\n",
    "corpus_dir = 'corpus'\n",
    "src_dir = 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:12:59.307968Z",
     "start_time": "2021-01-10T17:12:59.305518Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:12:59.524405Z",
     "start_time": "2021-01-10T17:12:59.521558Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir, src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:12:59.728138Z",
     "start_time": "2021-01-10T17:12:59.725500Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'alaska'\n",
    "test_name = 'sampling_records_and_terms_test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:12:59.946773Z",
     "start_time": "2021-01-10T17:12:59.943175Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_filename = f'{dataset_name}_corpus.json'\n",
    "corpus_filepath = os.path.join(root_dir, data_dir, corpus_dir, corpus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:00.181149Z",
     "start_time": "2021-01-10T17:13:00.176938Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks_filename = f'{dataset_name}_chunks.json'\n",
    "chunks_filepath = os.path.join(root_dir, data_dir, corpus_dir, chunks_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:01.354904Z",
     "start_time": "2021-01-10T17:13:00.441015Z"
    }
   },
   "outputs": [],
   "source": [
    "from training import TrainingCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:01.375614Z",
     "start_time": "2021-01-10T17:13:01.357042Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()\n",
    "corpus.load(corpus_filepath)\n",
    "corpus.load_chunks(chunks_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:05.518972Z",
     "start_time": "2021-01-10T17:13:03.113319Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import TensorflowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:05.523120Z",
     "start_time": "2021-01-10T17:13:05.520600Z"
    }
   },
   "outputs": [],
   "source": [
    "models_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:05.528324Z",
     "start_time": "2021-01-10T17:13:05.525391Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename = f'{dataset_name}_nn_model.h5'\n",
    "model_filepath = os.path.join(root_dir, data_dir, models_dir, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:05.532916Z",
     "start_time": "2021-01-10T17:13:05.530175Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_filename = f'{dataset_name}_nn_word_index.csv'\n",
    "word_index_filepath = os.path.join(root_dir, data_dir, models_dir, word_index_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:07.587254Z",
     "start_time": "2021-01-10T17:13:05.534688Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/anaconda3/envs/testenv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_model = TensorflowModel(model_filepath, word_index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:10.268370Z",
     "start_time": "2021-01-10T17:13:10.262605Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:12.485028Z",
     "start_time": "2021-01-10T17:13:10.477618Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_model = load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to load a subset of `tf_model` such that the last layer is the LSTM layer. Using this neural network we can get for each input its corresponding embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:12.492233Z",
     "start_time": "2021-01-10T17:13:12.486939Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\tLayer\n",
      "-------------------------\n",
      "0 \t input_1\n",
      "1 \t embedding_1\n",
      "2 \t bidirectional_1\n",
      "3 \t dense_1\n",
      "4 \t dense_2\n"
     ]
    }
   ],
   "source": [
    "print('Index\\tLayer')\n",
    "print('-------------------------')\n",
    "for index, layer in enumerate(tf_model.layers):\n",
    "    print(index,'\\t',layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:14.207027Z",
     "start_time": "2021-01-10T17:13:14.202036Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = Model(tf_model.input, tf_model.get_layer(index=2).output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:14.857124Z",
     "start_time": "2021-01-10T17:13:14.705158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"424pt\" height=\"215pt\" viewBox=\"0.00 0.00 436.00 221.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(.9722 .9722) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-217 432,-217 432,4 -4,4\"/>\n",
       "<!-- 139650125873216 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>139650125873216</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"86,-166.5 86,-212.5 342,-212.5 342,-166.5 86,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.5\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"211,-166.5 211,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"211,-189.5 266,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"266,-166.5 266,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"266,-189.5 342,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "</g>\n",
       "<!-- 139650125873360 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>139650125873360</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-83.5 54,-129.5 374,-129.5 374,-83.5 54,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"215,-83.5 215,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"215,-106.5 270,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"270,-83.5 270,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"270,-106.5 374,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42, 200)</text>\n",
       "</g>\n",
       "<!-- 139650125873216&#45;&gt;139650125873360 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>139650125873216-&gt;139650125873360</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M214,-166.3799C214,-158.1745 214,-148.7679 214,-139.8786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.5001,-139.784 214,-129.784 210.5001,-139.784 217.5001,-139.784\"/>\n",
       "</g>\n",
       "<!-- 139650125873456 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>139650125873456</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"0,-.5 0,-46.5 428,-46.5 428,-.5 0,-.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"269,-.5 269,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"296.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"269,-23.5 324,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"296.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"324,-.5 324,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42, 200)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"324,-23.5 428,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 139650125873360&#45;&gt;139650125873456 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>139650125873360-&gt;139650125873456</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M214,-83.3799C214,-75.1745 214,-65.7679 214,-56.8786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.5001,-56.784 214,-46.784 210.5001,-56.784 217.5001,-56.784\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(embedding_model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve embeddings using the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:18.914661Z",
     "start_time": "2021-01-10T17:13:18.910684Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:19.136289Z",
     "start_time": "2021-01-10T17:13:19.125138Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_df = pd.read_csv(word_index_filepath, index_col='term')\n",
    "word_to_idx_map = word_index_df.to_dict()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:19.343386Z",
     "start_time": "2021-01-10T17:13:19.338104Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def tokens_to_sequence(tokens, word_to_idx_map, maxlen):\n",
    "    sequence = []\n",
    "    for token in tokens:\n",
    "        if token in word_to_idx_map:\n",
    "            token_idx = word_to_idx_map[token]\n",
    "            sequence.append(token_idx)\n",
    "    \n",
    "    padded_sequence = pad_sequences([sequence], maxlen=maxlen).reshape(-1)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:19.879473Z",
     "start_time": "2021-01-10T17:13:19.874525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = tf_model.input.shape[1]\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:20.773190Z",
     "start_time": "2021-01-10T17:13:20.770657Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:21.216163Z",
     "start_time": "2021-01-10T17:13:21.133442Z"
    }
   },
   "outputs": [],
   "source": [
    "for doc_id in corpus.docs:\n",
    "    doc_tokens = corpus.get_tokens(doc_id)\n",
    "    doc_sequence = tokens_to_sequence(doc_tokens, word_to_idx_map, maxlen)\n",
    "    doc_sequences.append(doc_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:21.377271Z",
     "start_time": "2021-01-10T17:13:21.371976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sequences_np = np.array(doc_sequences)\n",
    "doc_sequences_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:22.566509Z",
     "start_time": "2021-01-10T17:13:21.635111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = embedding_model.predict(doc_sequences_np)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample documents using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:23.490517Z",
     "start_time": "2021-01-10T17:13:22.568377Z"
    }
   },
   "outputs": [],
   "source": [
    "label_to_data_idx_map = nn_model.label_to_data_idx(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:23.525347Z",
     "start_time": "2021-01-10T17:13:23.492620Z"
    }
   },
   "outputs": [],
   "source": [
    "from sample import KMeansSampler\n",
    "\n",
    "sampler = KMeansSampler(corpus, \n",
    "                        embedding_matrix,\n",
    "                        label_to_data_idx_map,\n",
    "                        min_size=50,\n",
    "                        max_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function used for sampling data for each concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:23.953388Z",
     "start_time": "2021-01-10T17:13:23.950229Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_data_mp(sampler, label_idx):\n",
    "    sample_data_idxs = sampler.sample_data(label_idx)\n",
    "    return (label_idx, sample_data_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of available CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:24.597446Z",
     "start_time": "2021-01-10T17:13:24.594224Z"
    }
   },
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:25.147950Z",
     "start_time": "2021-01-10T17:13:25.135195Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_count(logical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of parallel job for the sampling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:26.298993Z",
     "start_time": "2021-01-10T17:13:26.295446Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_jobs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:27.022696Z",
     "start_time": "2021-01-10T17:13:27.019149Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.004660Z",
     "start_time": "2021-01-10T17:13:27.470398Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of  20 | elapsed:    4.4s remaining:    6.6s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  20 | elapsed:    4.5s remaining:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  20 | elapsed:    4.7s remaining:    2.0s\n",
      "[Parallel(n_jobs=8)]: Done  17 out of  20 | elapsed:    5.2s remaining:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    5.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "label_to_sample_idxs = Parallel(n_jobs=kmeans_jobs, verbose=10)(delayed(sample_data_mp)(sampler, label_idx) for label_idx in label_to_data_idx_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relevant terms for each cluster label using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility function for multicore processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.011810Z",
     "start_time": "2021-01-10T17:13:33.006602Z"
    }
   },
   "outputs": [],
   "source": [
    "from termfinder import LimeTermFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.017873Z",
     "start_time": "2021-01-10T17:13:33.013523Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_relevant_terms_mp(model, corpus, input_data):\n",
    "    result_list = []\n",
    "    \n",
    "    term_finder = LimeTermFinder(model, corpus, min_fts=15, max_fts=30)\n",
    "    \n",
    "    for label_idx, data_idx in input_data:\n",
    "        relevant_terms = term_finder.get_relevant_terms(data_idx, label_idx)\n",
    "        \n",
    "        if relevant_terms:\n",
    "            \n",
    "            for term, weight in relevant_terms.items():\n",
    "                dict_entry = {'label': corpus.labels[label_idx],\n",
    "                              'term': term,\n",
    "                              'weight': weight,\n",
    "                              'data_id': corpus.docs[data_idx]}\n",
    "                result_list.append(dict_entry)\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into multiple batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.022787Z",
     "start_time": "2021-01-10T17:13:33.019381Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = np.array([(label_idx, data_idx) for label_idx, data_idxs in label_to_sample_idxs for data_idx in data_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of parallel jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.026362Z",
     "start_time": "2021-01-10T17:13:33.024303Z"
    }
   },
   "outputs": [],
   "source": [
    "lime_jobs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:13:33.029982Z",
     "start_time": "2021-01-10T17:13:33.027689Z"
    }
   },
   "outputs": [],
   "source": [
    "input_slices = np.array_split(input_data, lime_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:28:12.789888Z",
     "start_time": "2020-09-22T15:28:12.783746Z"
    }
   },
   "source": [
    "Finally, find relevant terms using `LIME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:27.400432Z",
     "start_time": "2021-01-10T17:13:34.981482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:  6.5min remaining: 19.4min\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:  6.5min remaining:  9.1min\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:  6.7min remaining:  4.8min\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:  7.2min remaining:  2.4min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:  8.9min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start_time = time.time()\n",
    "terms_list_tmp = Parallel(n_jobs=lime_jobs, verbose=10, batch_size=1)(delayed(get_relevant_terms_mp)(nn_model, corpus, input_batch) for input_batch in input_slices)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:33.618988Z",
     "start_time": "2021-01-10T17:22:33.611375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:08:52.414227\n"
     ]
    }
   ],
   "source": [
    "delta_t = end_time - start_time\n",
    "elapsed_time = str(datetime.timedelta(seconds=delta_t))\n",
    "print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a DataFrame out of `terms_list_tmp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:37.729292Z",
     "start_time": "2021-01-10T17:22:37.724845Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for sublist in terms_list_tmp:\n",
    "    df_data += sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:46.606701Z",
     "start_time": "2021-01-10T17:22:46.600702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTITY#44',\n",
       "  'term': 'nikon_d3200_digital_camera_body',\n",
       "  'weight': 0.8970025770232101,\n",
       "  'data_id': 180},\n",
       " {'label': 'ENTITY#44',\n",
       "  'term': 'd3200',\n",
       "  'weight': 0.4765042327764458,\n",
       "  'data_id': 73},\n",
       " {'label': 'ENTITY#44',\n",
       "  'term': '24',\n",
       "  'weight': 0.28851455332782855,\n",
       "  'data_id': 73}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:52.172443Z",
     "start_time": "2021-01-10T17:22:52.163144Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_terms_df = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:52.598868Z",
     "start_time": "2021-01-10T17:22:52.582388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon_d3200_digital_camera_body</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>d3200</td>\n",
       "      <td>0.476504</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>24</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon</td>\n",
       "      <td>0.159362</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>slr</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                             term    weight  data_id\n",
       "0  ENTITY#44  nikon_d3200_digital_camera_body  0.897003      180\n",
       "1  ENTITY#44                            d3200  0.476504       73\n",
       "2  ENTITY#44                               24  0.288515       73\n",
       "3  ENTITY#44                            nikon  0.159362       73\n",
       "4  ENTITY#44                              slr  0.114818       73"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_terms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save retrieved terms to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:55.840600Z",
     "start_time": "2021-01-10T17:22:55.836026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/terms/relevant_terms_alaska_nn_sampling_records_and_terms_test1.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_dir = 'terms'\n",
    "filename = f'relevant_terms_{dataset_name}_nn_{test_name}.csv'\n",
    "filepath = os.path.join(root_dir, data_dir, terms_dir, filename)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:58.133174Z",
     "start_time": "2021-01-10T17:22:58.101225Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_terms_df.to_csv(filepath, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for pending joblib processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:22:59.586955Z",
     "start_time": "2021-01-10T17:22:59.583988Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import active_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:35:21.511858Z",
     "start_time": "2021-01-10T17:35:21.507573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
