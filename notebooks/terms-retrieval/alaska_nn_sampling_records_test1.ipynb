{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find cluster related terms using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:45.050566Z",
     "start_time": "2021-01-10T17:36:45.042566Z"
    }
   },
   "outputs": [],
   "source": [
    "root_dir = '../..'\n",
    "data_dir = 'data'\n",
    "corpus_dir = 'corpus'\n",
    "src_dir = 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:45.224181Z",
     "start_time": "2021-01-10T17:36:45.218452Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:45.426169Z",
     "start_time": "2021-01-10T17:36:45.419005Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(root_dir, src_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:45.619574Z",
     "start_time": "2021-01-10T17:36:45.613207Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'alaska'\n",
    "test_name = 'sampling_records_test1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:45.805682Z",
     "start_time": "2021-01-10T17:36:45.801063Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus_filename = f'{dataset_name}_corpus.json'\n",
    "corpus_filepath = os.path.join(root_dir, data_dir, corpus_dir, corpus_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:46.006718Z",
     "start_time": "2021-01-10T17:36:46.003735Z"
    }
   },
   "outputs": [],
   "source": [
    "chunks_filename = f'{dataset_name}_chunks.json'\n",
    "chunks_filepath = os.path.join(root_dir, data_dir, corpus_dir, chunks_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:47.194708Z",
     "start_time": "2021-01-10T17:36:46.200645Z"
    }
   },
   "outputs": [],
   "source": [
    "from training import TrainingCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:47.214159Z",
     "start_time": "2021-01-10T17:36:47.196398Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = TrainingCorpus()\n",
    "corpus.load(corpus_filepath)\n",
    "corpus.load_chunks(chunks_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:50.228236Z",
     "start_time": "2021-01-10T17:36:47.438060Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from model import TensorflowModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:50.234142Z",
     "start_time": "2021-01-10T17:36:50.230904Z"
    }
   },
   "outputs": [],
   "source": [
    "models_dir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:50.242510Z",
     "start_time": "2021-01-10T17:36:50.238599Z"
    }
   },
   "outputs": [],
   "source": [
    "model_filename = f'{dataset_name}_nn_model.h5'\n",
    "model_filepath = os.path.join(root_dir, data_dir, models_dir, model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:50.247556Z",
     "start_time": "2021-01-10T17:36:50.244984Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_filename = f'{dataset_name}_nn_word_index.csv'\n",
    "word_index_filepath = os.path.join(root_dir, data_dir, models_dir, word_index_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:52.752317Z",
     "start_time": "2021-01-10T17:36:50.249351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nvidia/anaconda3/envs/testenv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nn_model = TensorflowModel(model_filepath, word_index_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:52.759395Z",
     "start_time": "2021-01-10T17:36:52.755024Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.078046Z",
     "start_time": "2021-01-10T17:36:52.761156Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_model = load_model(model_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all we need to load a subset of `tf_model` such that the last layer is the LSTM layer. Using this neural network we can get for each input its corresponding embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.085380Z",
     "start_time": "2021-01-10T17:36:55.080322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index\tLayer\n",
      "-------------------------\n",
      "0 \t input_1\n",
      "1 \t embedding_1\n",
      "2 \t bidirectional_1\n",
      "3 \t dense_1\n",
      "4 \t dense_2\n"
     ]
    }
   ],
   "source": [
    "print('Index\\tLayer')\n",
    "print('-------------------------')\n",
    "for index, layer in enumerate(tf_model.layers):\n",
    "    print(index,'\\t',layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.091202Z",
     "start_time": "2021-01-10T17:36:55.087542Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = Model(tf_model.input, tf_model.get_layer(index=2).output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.203239Z",
     "start_time": "2021-01-10T17:36:55.092766Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"424pt\" height=\"215pt\" viewBox=\"0.00 0.00 436.00 221.00\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(.9722 .9722) rotate(0) translate(4 217)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-217 432,-217 432,4 -4,4\"/>\n",
       "<!-- 140615754078480 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>140615754078480</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"86,-166.5 86,-212.5 342,-212.5 342,-166.5 86,-166.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.5\" y=\"-185.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input_1: InputLayer</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"211,-166.5 211,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"211,-189.5 266,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"238.5\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"266,-166.5 266,-212.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-197.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"266,-189.5 342,-189.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"304\" y=\"-174.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "</g>\n",
       "<!-- 140615754076560 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>140615754076560</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"54,-83.5 54,-129.5 374,-129.5 374,-83.5 54,-83.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-102.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"215,-83.5 215,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"215,-106.5 270,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"242.5\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"270,-83.5 270,-129.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-114.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"270,-106.5 374,-106.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"322\" y=\"-91.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42, 200)</text>\n",
       "</g>\n",
       "<!-- 140615754078480&#45;&gt;140615754076560 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>140615754078480-&gt;140615754076560</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M214,-166.3799C214,-158.1745 214,-148.7679 214,-139.8786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.5001,-139.784 214,-129.784 210.5001,-139.784 217.5001,-139.784\"/>\n",
       "</g>\n",
       "<!-- 140615754076272 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>140615754076272</title>\n",
       "<polygon fill=\"none\" stroke=\"#000000\" points=\"0,-.5 0,-46.5 428,-46.5 428,-.5 0,-.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"134.5\" y=\"-19.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"269,-.5 269,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"296.5\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">input:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"269,-23.5 324,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"296.5\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">output:</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"324,-.5 324,-46.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-31.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 42, 200)</text>\n",
       "<polyline fill=\"none\" stroke=\"#000000\" points=\"324,-23.5 428,-23.5 \"/>\n",
       "<text text-anchor=\"middle\" x=\"376\" y=\"-8.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">(None, 200)</text>\n",
       "</g>\n",
       "<!-- 140615754076560&#45;&gt;140615754076272 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>140615754076560-&gt;140615754076272</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M214,-83.3799C214,-75.1745 214,-65.7679 214,-56.8786\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"217.5001,-56.784 214,-46.784 210.5001,-56.784 217.5001,-56.784\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(embedding_model, show_shapes=True, dpi=70).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve embeddings using the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.207598Z",
     "start_time": "2021-01-10T17:36:55.205116Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.217675Z",
     "start_time": "2021-01-10T17:36:55.209224Z"
    }
   },
   "outputs": [],
   "source": [
    "word_index_df = pd.read_csv(word_index_filepath, index_col='term')\n",
    "word_to_idx_map = word_index_df.to_dict()['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.224142Z",
     "start_time": "2021-01-10T17:36:55.219287Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def tokens_to_sequence(tokens, word_to_idx_map, maxlen):\n",
    "    sequence = []\n",
    "    for token in tokens:\n",
    "        if token in word_to_idx_map:\n",
    "            token_idx = word_to_idx_map[token]\n",
    "            sequence.append(token_idx)\n",
    "    \n",
    "    padded_sequence = pad_sequences([sequence], maxlen=maxlen).reshape(-1)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.229179Z",
     "start_time": "2021-01-10T17:36:55.225760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen = tf_model.input.shape[1]\n",
    "maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.232906Z",
     "start_time": "2021-01-10T17:36:55.230665Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_sequences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.303259Z",
     "start_time": "2021-01-10T17:36:55.234493Z"
    }
   },
   "outputs": [],
   "source": [
    "for doc_id in corpus.docs:\n",
    "    doc_tokens = corpus.get_tokens(doc_id)\n",
    "    doc_sequence = tokens_to_sequence(doc_tokens, word_to_idx_map, maxlen)\n",
    "    doc_sequences.append(doc_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:55.497637Z",
     "start_time": "2021-01-10T17:36:55.491849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sequences_np = np.array(doc_sequences)\n",
    "doc_sequences_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:36:57.574427Z",
     "start_time": "2021-01-10T17:36:56.356579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2171, 200)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = embedding_model.predict(doc_sequences_np)\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample documents using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:01.767633Z",
     "start_time": "2021-01-10T17:37:00.600188Z"
    }
   },
   "outputs": [],
   "source": [
    "label_to_data_idx_map = nn_model.label_to_data_idx(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:01.797808Z",
     "start_time": "2021-01-10T17:37:01.769538Z"
    }
   },
   "outputs": [],
   "source": [
    "from sample import KMeansSampler\n",
    "\n",
    "sampler = KMeansSampler(corpus, \n",
    "                        embedding_matrix,\n",
    "                        label_to_data_idx_map,\n",
    "                        min_size=50,\n",
    "                        max_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility function used for sampling data for each concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:01.883235Z",
     "start_time": "2021-01-10T17:37:01.879221Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_data_mp(sampler, label_idx):\n",
    "    sample_data_idxs = sampler.sample_data(label_idx)\n",
    "    return (label_idx, sample_data_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the number of available CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:03.051132Z",
     "start_time": "2021-01-10T17:37:03.047960Z"
    }
   },
   "outputs": [],
   "source": [
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:03.541596Z",
     "start_time": "2021-01-10T17:37:03.532443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psutil.cpu_count(logical=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of parallel job for the sampling step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:04.894142Z",
     "start_time": "2021-01-10T17:37:04.890765Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans_jobs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:05.795641Z",
     "start_time": "2021-01-10T17:37:05.791341Z"
    }
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:13.028953Z",
     "start_time": "2021-01-10T17:37:06.987395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=8)]: Done   8 out of  20 | elapsed:    4.9s remaining:    7.4s\n",
      "[Parallel(n_jobs=8)]: Done  11 out of  20 | elapsed:    5.1s remaining:    4.2s\n",
      "[Parallel(n_jobs=8)]: Done  14 out of  20 | elapsed:    5.2s remaining:    2.2s\n",
      "[Parallel(n_jobs=8)]: Done  17 out of  20 | elapsed:    5.9s remaining:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    6.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done  20 out of  20 | elapsed:    6.0s finished\n"
     ]
    }
   ],
   "source": [
    "label_to_sample_idxs = Parallel(n_jobs=kmeans_jobs, verbose=10)(delayed(sample_data_mp)(sampler, label_idx) for label_idx in label_to_data_idx_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relevant terms for each cluster label using LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility function for multicore processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:14.825748Z",
     "start_time": "2021-01-10T17:37:14.814848Z"
    }
   },
   "outputs": [],
   "source": [
    "from termfinder import LimeTermFinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:15.063539Z",
     "start_time": "2021-01-10T17:37:15.054891Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_relevant_terms_mp(model, corpus, input_data):\n",
    "    result_list = []\n",
    "    \n",
    "    term_finder = LimeTermFinder(model, corpus)\n",
    "    \n",
    "    for label_idx, data_idx in input_data:\n",
    "        relevant_terms = term_finder.get_relevant_terms(data_idx, label_idx)\n",
    "        \n",
    "        if relevant_terms:\n",
    "            \n",
    "            for term, weight in relevant_terms.items():\n",
    "                dict_entry = {'label': corpus.labels[label_idx],\n",
    "                              'term': term,\n",
    "                              'weight': weight,\n",
    "                              'data_id': corpus.docs[data_idx]}\n",
    "                result_list.append(dict_entry)\n",
    "    \n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into multiple batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:15.566799Z",
     "start_time": "2021-01-10T17:37:15.561785Z"
    }
   },
   "outputs": [],
   "source": [
    "input_data = np.array([(label_idx, data_idx) for label_idx, data_idxs in label_to_sample_idxs for data_idx in data_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of parallel jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:16.141424Z",
     "start_time": "2021-01-10T17:37:16.138534Z"
    }
   },
   "outputs": [],
   "source": [
    "lime_jobs = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:37:16.758870Z",
     "start_time": "2021-01-10T17:37:16.754725Z"
    }
   },
   "outputs": [],
   "source": [
    "input_slices = np.array_split(input_data, lime_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T15:28:12.789888Z",
     "start_time": "2020-09-22T15:28:12.783746Z"
    }
   },
   "source": [
    "Finally, find relevant terms using `LIME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:46:28.446785Z",
     "start_time": "2021-01-10T17:37:17.694525Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   1 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  12 | elapsed:  8.9min remaining: 26.7min\n",
      "[Parallel(n_jobs=12)]: Done   5 out of  12 | elapsed:  8.9min remaining: 12.5min\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  12 | elapsed:  9.0min remaining:  6.4min\n",
      "[Parallel(n_jobs=12)]: Done   9 out of  12 | elapsed:  9.0min remaining:  3.0min\n",
      "[Parallel(n_jobs=12)]: Done  12 out of  12 | elapsed:  9.2min finished\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "start_time = time.time()\n",
    "terms_list_tmp = Parallel(n_jobs=lime_jobs, verbose=10, batch_size=1)(delayed(get_relevant_terms_mp)(nn_model, corpus, input_batch) for input_batch in input_slices)\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:40.711825Z",
     "start_time": "2021-01-10T17:56:40.707199Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0:09:10.745695\n"
     ]
    }
   ],
   "source": [
    "delta_t = end_time - start_time\n",
    "elapsed_time = str(datetime.timedelta(seconds=delta_t))\n",
    "print(f'Elapsed time: {elapsed_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a DataFrame out of `terms_list_tmp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:44.064391Z",
     "start_time": "2021-01-10T17:56:44.060295Z"
    }
   },
   "outputs": [],
   "source": [
    "df_data = []\n",
    "for sublist in terms_list_tmp:\n",
    "    df_data += sublist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:44.639512Z",
     "start_time": "2021-01-10T17:56:44.633133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'ENTITY#44',\n",
       "  'term': 'nikon_d3200_digital_camera_body',\n",
       "  'weight': 0.8970025770232101,\n",
       "  'data_id': 180},\n",
       " {'label': 'ENTITY#44',\n",
       "  'term': 'd3200',\n",
       "  'weight': 0.4765042327764458,\n",
       "  'data_id': 73},\n",
       " {'label': 'ENTITY#44',\n",
       "  'term': '24',\n",
       "  'weight': 0.28851455332782855,\n",
       "  'data_id': 73}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:47.558100Z",
     "start_time": "2021-01-10T17:56:47.542814Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_terms_df = pd.DataFrame(df_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:48.122846Z",
     "start_time": "2021-01-10T17:56:48.103633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "      <th>data_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon_d3200_digital_camera_body</td>\n",
       "      <td>0.897003</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>d3200</td>\n",
       "      <td>0.476504</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>24</td>\n",
       "      <td>0.288515</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>nikon</td>\n",
       "      <td>0.159362</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTITY#44</td>\n",
       "      <td>slr</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                             term    weight  data_id\n",
       "0  ENTITY#44  nikon_d3200_digital_camera_body  0.897003      180\n",
       "1  ENTITY#44                            d3200  0.476504       73\n",
       "2  ENTITY#44                               24  0.288515       73\n",
       "3  ENTITY#44                            nikon  0.159362       73\n",
       "4  ENTITY#44                              slr  0.114818       73"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_terms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save retrieved terms to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:51.248594Z",
     "start_time": "2021-01-10T17:56:51.242033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../data/terms/relevant_terms_alaska_nn_sampling_records_test1.csv'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_dir = 'terms'\n",
    "filename = f'relevant_terms_{dataset_name}_nn_{test_name}.csv'\n",
    "filepath = os.path.join(root_dir, data_dir, terms_dir, filename)\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:54.963586Z",
     "start_time": "2021-01-10T17:56:54.928862Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_terms_df.to_csv(filepath, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for pending joblib processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:56:59.987861Z",
     "start_time": "2021-01-10T17:56:59.983696Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import active_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-10T17:57:03.614857Z",
     "start_time": "2021-01-10T17:57:03.611371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_children()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
